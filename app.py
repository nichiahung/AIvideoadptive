#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AdaptVideo - DOOHå½±ç‰‡å°ºå¯¸è½‰æ›å·¥å…· (æœ¬åœ°éƒ¨ç½²ç‰ˆ)
"""

import os
import sys
import shutil
from datetime import datetime
import uuid
import cv2
import numpy as np
import base64
import json
import shelve
from contextlib import closing
from werkzeug.utils import secure_filename
from flask import Flask, request, jsonify, render_template, send_from_directory, abort
from flask_cors import CORS
from dotenv import load_dotenv
import httpx
from openai import OpenAI
import tempfile
import time
from io import BytesIO
from PIL import Image, ImageDraw

# --- åˆå§‹åŒ–èˆ‡è¨­å®š ---

# åŠ è¼‰ .env æ–‡ä»¶
load_dotenv()

# å¸¸æ•¸è¨­å®š
APP_ROOT = os.path.dirname(os.path.abspath(__file__))
UPLOAD_FOLDER = os.path.join(APP_ROOT, 'uploads')
OUTPUT_FOLDER = os.path.join(APP_ROOT, 'outputs')
SHELVE_FILE = os.path.join(APP_ROOT, 'video_data.db')
MAX_FILE_SIZE = 500 * 1024 * 1024  # 500MB

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# å˜—è©¦å°å…¥ MoviePy
try:
    from moviepy.editor import VideoFileClip
    MOVIEPY_AVAILABLE = True
    print("âœ… MoviePy å·²è¼‰å…¥ï¼Œæ”¯æ´å®Œæ•´å½±ç‰‡è½‰æ›åŠŸèƒ½")
except ImportError:
    MOVIEPY_AVAILABLE = False
    print("âš ï¸ MoviePy æœªå®‰è£ï¼Œå°‡ä½¿ç”¨åŸºæœ¬åŠŸèƒ½")

# åˆå§‹åŒ– OpenAI ç”¨æˆ¶ç«¯
try:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("åœ¨ .env æ–‡ä»¶æˆ–ç’°å¢ƒè®Šæ•¸ä¸­æ‰¾ä¸åˆ° OPENAI_API_KEYã€‚")
    http_client = httpx.Client(proxies={})
    client = OpenAI(api_key=api_key, http_client=http_client)
    LLM_AI_AVAILABLE = True
    print("âœ… OpenAI ç”¨æˆ¶ç«¯å·²æˆåŠŸåˆå§‹åŒ–ã€‚")
except Exception as e:
    client = None
    LLM_AI_AVAILABLE = False
    print(f"âš ï¸ ç„¡æ³•åˆå§‹åŒ– OpenAI ç”¨æˆ¶ç«¯: {e}")

# åŠ è¼‰ OpenCV äººè‡‰åµæ¸¬æ¨¡å‹
try:
    face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
    face_cascade = cv2.CascadeClassifier(face_cascade_path)
    if face_cascade.empty():
        raise IOError(f"ç„¡æ³•å¾è·¯å¾‘åŠ è¼‰ haarcascade: {face_cascade_path}")
    OPENCV_AI_AVAILABLE = True
    print("âœ… OpenCV äººè‡‰åµæ¸¬æ¨¡å‹å·²è¼‰å…¥")
except Exception as e:
    OPENCV_AI_AVAILABLE = False
    print(f"âš ï¸ ç„¡æ³•è¼‰å…¥OpenCVäººè‡‰åµæ¸¬æ¨¡å‹: {e}")

# DOOH å°ºå¯¸æ¨¡æ¿
DOOH_TEMPLATES = [
    {"name": "é«˜é›„ç‰ˆä½", "width": 3840, "height": 1526, "description": "é«˜é›„LEDçœ‹æ¿å°ˆç”¨å°ºå¯¸"},
    {"name": "å¿ å­å•†åœˆ", "width": 1440, "height": 960, "description": "å¿ å­å•†åœˆæ•¸ä½çœ‹æ¿"},
    {"name": "æ¨™æº–16:9", "width": 1920, "height": 1080, "description": "æ¨™æº–Full HDå°ºå¯¸"},
    {"name": "4Kæ©«å±", "width": 3840, "height": 2160, "description": "4K Ultra HDæ©«å±"},
    {"name": "è±å±9:16", "width": 1080, "height": 1920, "description": "æ‰‹æ©Ÿè±å±æ¯”ä¾‹"},
    {"name": "æ–¹å½¢1:1", "width": 1080, "height": 1080, "description": "æ­£æ–¹å½¢é¡¯ç¤º"},
    {"name": "è¶…å¯¬å±", "width": 2560, "height": 1080, "description": "21:9è¶…å¯¬å±å¹•"}
]

# --- Flask App ---
app = Flask(__name__)
CORS(app)

# --- æ ¸å¿ƒåˆ†æèˆ‡è½‰æ›å‡½å¼ ---

def get_video_info(file_path):
    """ç²å–å½±ç‰‡åŸºæœ¬ä¿¡æ¯"""
    try:
        with VideoFileClip(file_path) as clip:
            return { "duration": round(clip.duration, 2), "width": clip.w, "height": clip.h, "fps": clip.fps }
    except Exception as e:
        print(f"ç²å–å½±ç‰‡ä¿¡æ¯å¤±æ•—: {e}")
        return { "duration": 0, "width": 0, "height": 0, "fps": 0 }

def extract_thumbnail(video_path):
    """å¾å½±ç‰‡ä¸­é–“æå–ä¸€å¹€ä½œç‚ºç¸®åœ–"""
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened(): return None
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames // 2)
        ret, frame = cap.read()
        cap.release()
        if not ret: return None
        _, buffer = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 75])
        return f"data:image/jpeg;base64,{base64.b64encode(buffer).decode('utf-8')}"
    except Exception as e:
        print(f"âŒ æå–ç¸®åœ–å¤±æ•—: {e}")
        return None

def analyze_video_for_face_crop(video_path):
    """åˆ†æå½±ç‰‡ï¼Œæ‰¾åˆ°ä¸»è¦äººè‡‰çš„å¹³å‡ä¸­å¿ƒä½ç½®"""
    if not OPENCV_AI_AVAILABLE: return None
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened(): return None

    face_positions = []
    max_frames_to_check = 90  # æœ€å¤šåˆ†æ90å¹€
    frame_count = 0
    while cap.isOpened() and frame_count < max_frames_to_check:
        ret, frame = cap.read()
        if not ret: break
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
        if len(faces) > 0:
            main_face = max(faces, key=lambda r: r[2] * r[3])
            face_positions.append((main_face[0] + main_face[2] / 2, main_face[1] + main_face[3] / 2))
        frame_count += 1
    cap.release()

    if not face_positions:
        print("â„¹ï¸ åœ¨å½±ç‰‡ä¸­æœªåµæ¸¬åˆ°äººè‡‰")
        return None
    
    avg_pos = np.mean(face_positions, axis=0)
    print(f"âœ… AIåˆ†æå®Œæˆï¼Œå¹³å‡äººè‡‰ä¸­å¿ƒ: ({avg_pos[0]:.0f}, {avg_pos[1]:.0f})")
    return avg_pos

def extract_frames_from_video(video_path, max_frames=5, attempt=1):
    """å¾å½±ç‰‡ä¸­æå–å¹€ï¼Œæ”¯æ´å¤šæ¬¡å˜—è©¦ä»¥ç²å¾—ä¸åŒçš„å¹€"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened(): 
        return []

    base64_frames = []
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    if total_frames <= 0:
        cap.release()
        return []
    
    # æ ¹æ“šå˜—è©¦æ¬¡æ•¸èª¿æ•´å¹€æå–ç­–ç•¥
    if attempt == 1:
        # ç¬¬ä¸€æ¬¡å˜—è©¦ï¼šå‡å‹»åˆ†ä½ˆ
        frame_interval = max(1, total_frames // max_frames)
        start_offset = 0
    elif attempt == 2:
        # ç¬¬äºŒæ¬¡å˜—è©¦ï¼šå¾å½±ç‰‡ä¸­é–“é–‹å§‹
        frame_interval = max(1, total_frames // (max_frames * 2))
        start_offset = total_frames // 4
    else:
        # ç¬¬ä¸‰æ¬¡å˜—è©¦ï¼šéš¨æ©Ÿé¸æ“‡å¹€
        import random
        frame_indices = random.sample(range(total_frames), min(max_frames, total_frames))
        frame_indices.sort()
        
        for frame_idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                _, buffer = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 75])
                base64_frames.append(base64.b64encode(buffer).decode("utf-8"))
        
        cap.release()
        return base64_frames
    
    # æ¨™æº–æå–é‚è¼¯ï¼ˆç¬¬ä¸€æ¬¡å’Œç¬¬äºŒæ¬¡å˜—è©¦ï¼‰
    count = 0
    for i in range(start_offset, total_frames, frame_interval):
        if count >= max_frames: break
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if ret:
            _, buffer = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 75])
            base64_frames.append(base64.b64encode(buffer).decode("utf-8"))
            count += 1
    
    cap.release()
    return base64_frames

def analyze_video_with_llm(video_path, conversation_history):
    """ä½¿ç”¨å¤šæ¨¡æ…‹LLMåˆ†æå½±ç‰‡ï¼ŒåŸºæ–¼æä¾›çš„å°è©±æ­·å²"""
    if not LLM_AI_AVAILABLE: return None
    
    base64_frames = extract_frames_from_video(video_path, max_frames=5)
    if not base64_frames:
        print("âŒ ç„¡æ³•æå–å¹€é€²è¡ŒLLMåˆ†æ")
        return None
        
    print(f"ğŸ§  å·²æå– {len(base64_frames)} å¹€ï¼Œæº–å‚™åŸºæ–¼å°è©±æ­·å²é€²è¡ŒLLMåˆ†æ...")

    template_descriptions = "\\n".join([f"- {t['name']}: {t['width']}x{t['height']} ({t['description']})" for t in DOOH_TEMPLATES])
    
    # æ§‹å»ºå‚³é€çµ¦OpenAIçš„messages
    messages = [
        {
            "role": "system",
            "content": f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„**æ•¸ä½æˆ¶å¤–å»£å‘Š (DOOH) ç‰ˆä½ç­–ç•¥ç¸½ç›£**ã€‚ä½ çš„ä»»å‹™æ˜¯åˆ†æç”¨æˆ¶æä¾›çš„å½±ç‰‡ï¼Œä¸¦ä»¥éŠ·å”®é¡§å•çš„å£å»ï¼Œæä¾›å°ˆæ³¨æ–¼ DOOH æ‡‰ç”¨å ´æ™¯çš„æ”¹é€ å»ºè­°ã€‚

**ä½ çš„è·è²¬:**
1.  **ç†è§£å°è©±ä¸Šä¸‹æ–‡**: å®Œæ•´é–±è®€ç”¨æˆ¶èˆ‡ä½ çš„å°è©±æ­·å²ï¼Œç†è§£ç”¨æˆ¶çš„æ„åœ–è®ŠåŒ–å’Œæ ¸å¿ƒè¨´æ±‚ã€‚
2.  **è­˜åˆ¥è¡ŒéŠ·ä¸»é«”**: åœ¨å½±ç‰‡ç•«é¢ä¸­æ‰¾å‡ºæœ€é‡è¦çš„è¡ŒéŠ·ä¸»é«”ï¼ˆä¾‹å¦‚ï¼šç”¢å“ã€Logoã€é—œéµäººç‰©ã€æ¨™èªï¼‰ã€‚
3.  **æä¾› DOOH ç‰ˆä½å»ºè­°**: æ ¹æ“šå½±ç‰‡å…§å®¹ï¼Œå¾å¯ç”¨æ¨¡æ¿æ¸…å–®ä¸­æ¨è–¦2-3å€‹æœ€é©åˆçš„å°ºå¯¸ã€‚å°æ–¼æ¯å€‹æ¨è–¦çš„å°ºå¯¸ï¼Œä½ å¿…é ˆåŒæ™‚æ¨è–¦1-2å€‹**å…·é«”çš„ DOOH å»£å‘Šç‰ˆä½**ï¼ˆä¾‹å¦‚ï¼šã€Œä¿¡ç¾©å€å•†åœˆ LED å¤§è¢å¹•ã€ã€ã€Œæ·é‹ç«™å…§æ•¸ä½çœ‹æ¿ã€ï¼‰ï¼Œä¸¦ç°¡è¦èªªæ˜ç†ç”±ã€‚
4.  **é‡è¦é™åˆ¶**: **ä½ çš„æ¨è–¦æ‡‰åš´æ ¼é™åˆ¶åœ¨ DOOH æ‡‰ç”¨å ´æ™¯ï¼Œä¸¦ä¸»å‹•é¿å…æå‡ºä»»ä½•ç¤¾ç¾¤åª’é«”å¹³å°ï¼ˆå¦‚ Instagram, TikTok, YouTubeï¼‰çš„å»ºè­°ã€‚**
5.  **æ ¼å¼åŒ–è¼¸å‡º**: ä½ çš„å›æ‡‰å¿…é ˆæ˜¯æ ¼å¼å®Œæ•´çš„ JSON ç‰©ä»¶ã€‚

**å¯ç”¨å°ºå¯¸æ¨¡æ¿:**
{template_descriptions}

**JSON è¼¸å‡ºæ ¼å¼ç¯„ä¾‹ (å°ˆæ³¨æ–¼ DOOH):**
{{
  "suggestions": "### AI å°ˆæ¥­å»ºè­°\\n\\næ ¹æ“šæ‚¨çš„å½±ç‰‡å…§å®¹ï¼Œé€™æ¬¾é‹å‹•é‹å……æ»¿å‹•æ„Ÿï¼Œæˆ‘æ¨è–¦ä»¥ä¸‹å…©ç¨® DOOH æŠ•æ”¾æ–¹æ¡ˆï¼š\\n\\n1.  **æ¨è–¦å°ºå¯¸ï¼šè±å±9:16 (1080x1920)**\\n    - **æœ€ä½³ç‰ˆä½**ï¼šéå¸¸é©åˆ **ç™¾è²¨å…¬å¸åŒ–å¦å“å°ˆæ«ƒçš„ç›´å¼è¢å¹•** æˆ– **é›»æ¢¯å…§çš„å»£å‘Šè¢å¹•**ã€‚é€™ç¨®æ ¼å¼èƒ½åœ¨æ¶ˆè²»è€…ç­‰å¾…æˆ–è¿‘è·é›¢ç§»å‹•æ™‚ï¼Œæœ‰æ•ˆå‚³éç”¢å“ç´°ç¯€ï¼Œå¸å¼•ç›®å…‰ã€‚\\n\\n2.  **æ¨è–¦å°ºå¯¸ï¼šæ¨™æº–16:9 (1920x1080)**\\n    - **æœ€ä½³ç‰ˆä½**ï¼šé©åˆæŠ•æ”¾åœ¨ **æ©Ÿå ´å‡ºå¢ƒå¤§å»³çš„é›»è¦–ç‰†** æˆ– **æ·é‹ç«™å…§çš„æ©«å¹…è¢å¹•**ã€‚é€™æ˜¯æœ€é€šç”¨çš„æ©«å‘æ ¼å¼ï¼Œèƒ½åœ¨å¤§é¢ç©å ´åœ°ä¸­ï¼Œæœ€å¤§åŒ–è¦–è¦ºè¡æ“ŠåŠ›ã€‚",
  "recommended_template_names": ["è±å±9:16", "æ¨™æº–16:9"],
  "analysis_options": [
    {{
      "subject": "ç™½è‰²é‹å‹•é‹",
      "importance": "high",
      "confidence": 0.95,
      "center": [960, 600],
      "thumbnail": "data:image/jpeg;base64,..."
    }}
  ]
}}

**è«‹åš´æ ¼éµå¾ªä»¥ä¸Š JSON æ ¼å¼é€²è¡Œè¼¸å‡ºã€‚**
"""
        }
    ]

    # å°‡åœ–åƒå¹€æ·»åŠ åˆ°ç¬¬ä¸€æ¢ç”¨æˆ¶æ¶ˆæ¯ï¼ˆå¦‚æœæ­·å²ç‚ºç©ºï¼‰æˆ–æœ€æ–°çš„ç”¨æˆ¶æ¶ˆæ¯
    user_content = []
    
    # é¦–å…ˆæ·»åŠ æ­·å²è¨˜éŒ„
    if conversation_history:
        messages.extend(conversation_history)
        # æ‰¾åˆ°æœ€å¾Œä¸€å€‹ç”¨æˆ¶æ¶ˆæ¯ä¾†é™„åŠ åœ–åƒ
        last_user_message = next((msg for msg in reversed(messages) if msg['role'] == 'user'), None)
        if last_user_message:
            # å¦‚æœæ˜¯å­—ä¸²ï¼Œè½‰æ›ç‚ºåˆ—è¡¨
            if isinstance(last_user_message['content'], str):
                last_user_message['content'] = [{"type": "text", "text": last_user_message['content']}]
            # é™„åŠ åœ–åƒ
            for frame in base64_frames:
                last_user_message['content'].append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{frame}"}})
        else: # å¦‚æœæ­·å²ä¸­æ²’æœ‰ç”¨æˆ¶æ¶ˆæ¯ï¼Œå‰µå»ºä¸€å€‹æ–°çš„
             messages.append({"role": "user", "content": [{"type": "text", "text": "è«‹åˆ†æé€™äº›ç•«é¢ã€‚"}] + [{"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{frame}"}} for frame in base64_frames]})

    else: # å¦‚æœæ²’æœ‰æ­·å²è¨˜éŒ„ï¼Œå‰µå»ºåˆå§‹ç”¨æˆ¶æ¶ˆæ¯
        user_content.append({"type": "text", "text": "é€™æ˜¯è¦åˆ†æçš„å½±ç‰‡ï¼Œè«‹æä¾›åˆå§‹å°ˆæ¥­å»ºè­°ã€‚"})
        for frame in base64_frames:
            user_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{frame}"}})
        messages.append({"role": "user", "content": user_content})

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            response_format={"type": "json_object"},
            temperature=0.3,
        )
        response_content = response.choices[0].message.content
        print("âœ… LLMåˆ†ææˆåŠŸ")
        return json.loads(response_content)
    except Exception as e:
        print(f"âŒ LLMåˆ†æå¤±æ•—: {e}")
        return None

def crop_frame_for_thumbnail(video_path, box):
    """å¾å½±ç‰‡ä¸­é–“å¹€è£åˆ‡ä¸€å€‹å€åŸŸä½œç‚ºç¸®åœ–"""
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened(): return None
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        # Seek to middle frame, which is usually representative
        cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames // 2) 
        ret, frame = cap.read()
        cap.release()
        
        if not ret: return None
        
        # é€²è¡Œè£åˆ‡
        x1, y1, x2, y2 = box
        cropped_frame = frame[y1:y2, x1:x2]
        
        # æª¢æŸ¥è£åˆ‡å¾Œçš„å½±æ ¼æ˜¯å¦æœ‰æ•ˆ
        if cropped_frame.size == 0:
            print(f"âš ï¸ è£åˆ‡å€åŸŸç„¡æ•ˆ: {box}, å°è‡´ç¸®åœ–ç”Ÿæˆå¤±æ•—ã€‚")
            return None

        _, buffer = cv2.imencode(".jpg", cropped_frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
        return f"data:image/jpeg;base64,{base64.b64encode(buffer).decode('utf-8')}"
    except Exception as e:
        print(f"âŒ ç‚ºç¸®åœ–è£åˆ‡å¹€æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def calculate_multi_subject_center_backend(selected_centers, file_id):
    """è¨ˆç®—å¤šå€‹ä¸»é«”çš„åŠ æ¬Šä¸­å¿ƒé»ï¼ˆå¾Œç«¯ç‰ˆæœ¬ï¼‰"""
    if not selected_centers or len(selected_centers) == 0:
        return None
    
    if len(selected_centers) == 1:
        return tuple(selected_centers[0])
    
    # ç²å– LLM åˆ†æçµæœä»¥å–å¾—é‡è¦æ€§å’Œä¿¡å¿ƒåº¦è³‡è¨Š
    with closing(shelve.open(SHELVE_FILE)) as db:
        video_data = db.get(file_id, {})
        analysis_options = video_data.get('llm_analysis_options', [])
    
    total_weighted_x = 0
    total_weighted_y = 0
    total_weight = 0
    
    for center in selected_centers:
        # æ‰¾åˆ°å°æ‡‰çš„åˆ†æé¸é …ä»¥ç²å–é‡è¦æ€§å’Œä¿¡å¿ƒåº¦
        importance = 'medium'  # é è¨­å€¼
        confidence = 0.8       # é è¨­å€¼
        
        for option in analysis_options:
            if option.get('center') == center:
                importance = option.get('importance', 'medium')
                confidence = option.get('confidence', 0.8)
                break
        
        # é‡è¦æ€§æ¬Šé‡
        importance_weights = {'high': 3, 'medium': 2, 'low': 1}
        importance_weight = importance_weights.get(importance, 2)
        
        # æœ€çµ‚æ¬Šé‡ = é‡è¦æ€§æ¬Šé‡ Ã— ä¿¡å¿ƒåº¦
        weight = importance_weight * confidence
        
        total_weighted_x += center[0] * weight
        total_weighted_y += center[1] * weight
        total_weight += weight
        
        print(f"ğŸ¯ ä¸»é«”ä¸­å¿ƒ {center}: é‡è¦æ€§={importance}, ä¿¡å¿ƒåº¦={confidence}, æ¬Šé‡={weight}")
    
    if total_weight > 0:
        final_center = (total_weighted_x / total_weight, total_weighted_y / total_weight)
        print(f"âœ… å¤šä¸»é«”åŠ æ¬Šä¸­å¿ƒé»: {final_center}")
        return final_center
    else:
        # å¦‚æœç„¡æ³•è¨ˆç®—æ¬Šé‡ï¼Œå‰‡ä½¿ç”¨ç°¡å–®å¹³å‡
        avg_x = sum(center[0] for center in selected_centers) / len(selected_centers)
        avg_y = sum(center[1] for center in selected_centers) / len(selected_centers)
        return (avg_x, avg_y)

def perform_video_conversion(input_path, output_path, target_width, target_height, crop_mode='center', manual_center=None):
    """æ ¸å¿ƒè½‰æ›å‡½å¼"""
    try:
        if not MOVIEPY_AVAILABLE:
            print("MoviePy ä¸å¯ç”¨ï¼ŒåŸ·è¡Œæª”æ¡ˆè¤‡è£½ã€‚")
            shutil.copy2(input_path, output_path)
            return

        print(f"â–¶ï¸ MoviePy: é–‹å§‹è½‰æ›ï¼Œè¼¸å‡ºè‡³: {output_path}")
            
        with VideoFileClip(input_path) as clip:
            crop_center = (clip.w / 2, clip.h / 2)

            if manual_center:
                print(f"ğŸ§  ä½¿ç”¨æ‰‹å‹•é¸æ“‡çš„ä¸­å¿ƒé»: {manual_center}")
                crop_center = manual_center
            elif crop_mode == 'face':
                print("ğŸ§  MoviePy: å•Ÿç”¨AIäººè‡‰è¾¨è­˜...")
                ai_center = analyze_video_for_face_crop(input_path)
                if ai_center is not None: crop_center = ai_center
            
            print("ğŸ“ MoviePy: è¨ˆç®—ç¸®æ”¾èˆ‡è£åˆ‡åƒæ•¸...")
            scale = max(target_width / clip.w, target_height / clip.h)
            resized_clip = clip.resize(scale)
            
            # --- æ™ºæ…§è£åˆ‡é‚Šç•Œè™•ç† ---
            # é€™æ˜¯æˆ‘å€‘å¸Œæœ›çš„ä¸­å¿ƒé»
            desired_center_x = crop_center[0] * scale
            desired_center_y = crop_center[1] * scale

            # è¨ˆç®—è£åˆ‡æ¡†çš„åŠå¯¬å’ŒåŠé«˜
            half_w = target_width / 2
            half_h = target_height / 2

            # è¨ˆç®—ä¸­å¿ƒé»å¯ä»¥ç§»å‹•çš„å®‰å…¨ç¯„åœ
            min_x = half_w
            max_x = resized_clip.w - half_w
            min_y = half_h
            max_y = resized_clip.h - half_h

            # ç¢ºä¿ä¸­å¿ƒé»ä¸æœƒè¶…å‡ºå®‰å…¨ç¯„åœï¼Œé¿å…è£åˆ‡åˆ°å½±ç‰‡å¤–çš„é»‘é‚Š
            final_crop_x = max(min_x, min(desired_center_x, max_x))
            final_crop_y = max(min_y, min(desired_center_y, max_y))

            if (final_crop_x, final_crop_y) != (desired_center_x, desired_center_y):
                print(f"âš ï¸ è£åˆ‡ä¸­å¿ƒé»å·²èª¿æ•´ä»¥é¿å…è¶…å‡ºé‚Šç•Œã€‚")
                print(f"   åŸå§‹ä¸­å¿ƒ: ({desired_center_x:.0f}, {desired_center_y:.0f}) -> èª¿æ•´å¾Œ: ({final_crop_x:.0f}, {final_crop_y:.0f})")

            final_clip = resized_clip.crop(
                x_center=final_crop_x, y_center=final_crop_y,
                width=target_width, height=target_height
            )
            
            temp_audio_filename = f"temp-audio-{uuid.uuid4()}.m4a"
            temp_audio_path = os.path.join(os.path.dirname(output_path), temp_audio_filename)

            print(f"âœï¸ MoviePy: é–‹å§‹å¯«å…¥è¼¸å‡ºæª”æ¡ˆè‡³ {output_path}")
            final_clip.write_videofile(
                str(output_path),
                codec='libx264', audio_codec='aac',
                temp_audiofile=str(temp_audio_path),
                remove_temp=True,
                verbose=False,
                logger=None
            )
            print("âœ… MoviePy: æª”æ¡ˆå¯«å…¥å®Œæˆã€‚")
            
            final_clip.close()
            resized_clip.close()
            
    except Exception as e:
        import traceback
        print(f"â€¼ï¸â€¼ï¸ MoviePy è½‰æ›æ ¸å¿ƒç™¼ç”Ÿè‡´å‘½éŒ¯èª¤ â€¼ï¸â€¼ï¸")
        print(traceback.format_exc())

    print("â³ ç­‰å¾…æ–‡ä»¶ç³»çµ±åŒæ­¥...")
    time.sleep(1)

# --- API Endpoints ---

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/templates')
def get_templates():
    return jsonify(DOOH_TEMPLATES)

@app.route('/api/upload', methods=['POST'])
def upload_video():
    if 'video' not in request.files:
        return jsonify({"error": "æ²’æœ‰é¸æ“‡æª”æ¡ˆ"}), 400
    file = request.files['video']
    if file.filename == '':
        return jsonify({"error": "æ²’æœ‰é¸æ“‡æª”æ¡ˆ"}), 400

    original_filename = secure_filename(file.filename)
    file_id = str(uuid.uuid4())
    upload_filename = f"{file_id}_original{os.path.splitext(file.filename)[1]}"
    upload_path = os.path.join(UPLOAD_FOLDER, upload_filename)
    file.save(upload_path)
    
    # ä½¿ç”¨çµ•å°è·¯å¾‘ä»¥å¢åŠ  OpenCV çš„ç©©å®šæ€§
    abs_upload_path = os.path.abspath(upload_path)

    video_info = get_video_info(abs_upload_path)
    thumbnail = extract_thumbnail(abs_upload_path)
    
    # å°‡å½±ç‰‡è³‡æ–™å­˜å…¥è³‡æ–™åº«
    with closing(shelve.open(SHELVE_FILE, writeback=True)) as db:
        db[file_id] = {
            "original_path": upload_path, # å„²å­˜ç›¸å°è·¯å¾‘ä»¥ä¿æŒå¯æ”œæ€§
            "video_info": video_info,
            "thumbnail_b64": thumbnail,
            "timestamp": datetime.now().isoformat()
        }

    return jsonify({
        "file_id": file_id,
        "video_info": video_info,
        "thumbnail": thumbnail
    })

@app.route('/api/analyze', methods=['POST'])
def analyze_video_api():
    """æ¥æ”¶å½±ç‰‡IDå’Œå°è©±æ­·å²ï¼Œè¿”å›LLMåˆ†æçµæœ"""
    data = request.get_json()
    if not data or 'file_id' not in data:
        return jsonify({"error": "ç¼ºå°‘ 'file_id'"}), 400

    file_id = data['file_id']
    conversation_history = data.get('conversation_history', []) # ç²å–å°è©±æ­·å²

    with closing(shelve.open(SHELVE_FILE)) as db:
        if file_id not in db:
            return jsonify({"error": "æ‰¾ä¸åˆ°æª”æ¡ˆ"}), 404
        video_record = db[file_id]

    video_path = video_record['original_path']
    if not os.path.exists(video_path):
        return jsonify({"error": "å½±ç‰‡æª”æ¡ˆä¸å­˜åœ¨"}), 404
    
    # å‚³éå°è©±æ­·å²çµ¦åˆ†æå‡½æ•¸
    analysis_result = analyze_video_with_llm(video_path, conversation_history)
    
    if not analysis_result:
        return jsonify({"error": "AIåˆ†æå½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤"}), 500
        
    # ç¢ºä¿ analysis_options å­˜åœ¨
    if 'analysis_options' not in analysis_result:
        analysis_result['analysis_options'] = []

    # ç‚ºæ¯å€‹åˆ†æé¸é …ç”Ÿæˆç¸®åœ–
    video_info = get_video_info(video_path)
    if video_info['width'] > 0 and video_info['height'] > 0:
        for option in analysis_result.get('analysis_options', []):
            center = option.get('center')
            if center:
                # å‡è¨­boxæ˜¯ç›¸å°æ–¼åŸå§‹å½±ç‰‡å°ºå¯¸
                box_size = 200 # ç¸®åœ–å¤§å°
                x, y = center
                
                # ç¢ºä¿è£åˆ‡æ¡†åœ¨å½±ç‰‡ç¯„åœå…§
                x1 = max(0, int(x - box_size / 2))
                y1 = max(0, int(y - box_size / 2))
                x2 = min(video_info['width'], int(x + box_size / 2))
                y2 = min(video_info['height'], int(y + box_size / 2))
                
                box = (x1, y1, x2, y2)
                thumbnail_b64 = crop_frame_for_thumbnail(video_path, box)
                option['thumbnail'] = thumbnail_b64

    return jsonify(analysis_result)

@app.route('/api/uploaded_videos', methods=['GET'])
def get_uploaded_videos():
    """ç²å–å·²ä¸Šå‚³å½±ç‰‡çš„åˆ—è¡¨"""
    videos = []
    with closing(shelve.open(SHELVE_FILE)) as db:
        # å°‡è³‡æ–™åº«ä¸­çš„é …ç›®æŒ‰æ™‚é–“å€’åºæ’åˆ—
        sorted_keys = sorted(db.keys(), key=lambda k: db[k].get('timestamp', ''), reverse=True)
        for key in sorted_keys:
            video_data = db.get(key)
            if video_data and 'original_path' in video_data:
                # åœ¨æ­¤æˆ‘å€‘ç›´æ¥å¾ video_info æˆ–ä¸€å€‹é è¨­è·¯å¾‘ç²å–
                # é€™è£¡æˆ‘å€‘ç°¡åŒ–è™•ç†ï¼Œç›´æ¥å›å‚³ file_id å’ŒåŸå§‹æª”å
                 videos.append({
                    "file_id": key,
                    "filename": os.path.basename(video_data['original_path']),
                    "thumbnail": video_data.get('thumbnail_b64'),
                    "video_info": video_data.get('video_info'),
                    "converted_videos": video_data.get('converted_videos', [])
                })
    return jsonify(videos)

@app.route('/api/convert', methods=['POST'])
def convert_video_api():
    """è™•ç†å½±ç‰‡è½‰æ›è«‹æ±‚"""
    print("--- æ”¶åˆ° /api/convert è«‹æ±‚ ---")
    print(f"è«‹æ±‚æ¨™é ­ (Headers): {request.headers}")
    
    if not request.is_json:
        print(f"âŒ éŒ¯èª¤: è«‹æ±‚çš„ Content-Type ä¸æ˜¯ application/jsonï¼Œè€Œæ˜¯ '{request.content_type}'ã€‚")
        return jsonify({"error": f"è«‹æ±‚çš„ Content-Type å¿…é ˆæ˜¯ application/jsonï¼Œä½†æ”¶åˆ°äº† '{request.content_type}'"}), 415

    data = request.json
    file_id = data.get('file_id')
    target_width = data.get('width')
    target_height = data.get('height')
    crop_mode = data.get('crop_mode', 'center')
    selected_subject_centers = data.get('centers')  # æ”¯æ´å¤šå€‹ä¸­å¿ƒé»
    selected_subject_center = data.get('center')    # å‘å¾Œç›¸å®¹å–®ä¸€ä¸­å¿ƒé»

    print(f"æ”¶åˆ°è½‰æ›è«‹æ±‚: file_id={file_id}, mode={crop_mode}, centers={selected_subject_centers}, center={selected_subject_center}")

    if not all([file_id, target_width, target_height]):
        return jsonify({"error": "ç¼ºå°‘å¿…è¦åƒæ•¸ (file_id, width, height)"}), 400

    upload_path = None
    original_file_ext = None
    for f in os.listdir(UPLOAD_FOLDER):
        if f.startswith(file_id):
            upload_path = os.path.join(UPLOAD_FOLDER, f)
            original_file_ext = os.path.splitext(f)[1]
            break

    if not upload_path:
        return jsonify({"error": f"æ‰¾ä¸åˆ° file_id ç‚º {file_id} çš„åŸå§‹æª”æ¡ˆ"}), 404

    output_filename = f"{file_id}_converted{original_file_ext}"
    output_path = os.path.join(OUTPUT_FOLDER, output_filename)
    
    manual_center = None
    if crop_mode == 'llm':
        # å„ªå…ˆä½¿ç”¨å¤šå€‹ä¸­å¿ƒé»ï¼Œå¦‚æœæ²’æœ‰å‰‡ä½¿ç”¨å–®ä¸€ä¸­å¿ƒé»
        if selected_subject_centers and len(selected_subject_centers) > 0:
            # è¨ˆç®—å¤šå€‹ä¸»é«”çš„åŠ æ¬Šä¸­å¿ƒé»
            manual_center = calculate_multi_subject_center_backend(selected_subject_centers, file_id)
            print(f"ğŸ¯ è¨ˆç®—å¤šä¸»é«”ä¸­å¿ƒé»: {manual_center}")
        elif selected_subject_center:
            manual_center = tuple(selected_subject_center)
            print(f"ğŸ¯ ä½¿ç”¨å–®ä¸€ä¸»é«”ä¸­å¿ƒé»: {manual_center}")
        else:
            # å¦‚æœä½¿ç”¨è€…é¸äº†LLMä½†æ²’æœ‰é¸ä¸»é«”ï¼Œå°±é€€å›åˆ°æ¨™æº–ç½®ä¸­
            print("âš ï¸ LLMæ¨¡å¼ä¸‹æœªæä¾›ä¸­å¿ƒé»ï¼Œå°‡é€€å›è‡³ä¸­å¿ƒè£åˆ‡ã€‚")
            crop_mode = 'center'
    
    print(f"ğŸš€ é–‹å§‹è½‰æ›: input={os.path.basename(upload_path)}, output={output_filename}, mode={crop_mode}, center={manual_center}")
    
    perform_video_conversion(
        input_path=upload_path,
        output_path=output_path,
        target_width=int(target_width),
        target_height=int(target_height),
        crop_mode=crop_mode,
        manual_center=manual_center
    )

    if not os.path.exists(output_path) or os.path.getsize(output_path) < 100:
        print(f"âŒ è½‰æ›å¾Œæª”æ¡ˆä¸å­˜åœ¨æˆ–æª”æ¡ˆéå°: {output_path}")
        return jsonify({"error": "å½±ç‰‡è½‰æ›å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¼ºæœå™¨æ—¥èªŒä»¥äº†è§£è©³æƒ…ã€‚"}), 500
        
    with closing(shelve.open(SHELVE_FILE, writeback=True)) as db:
        if file_id not in db:
            db[file_id] = {}
        db[file_id].update({
            "original_path": upload_path,
            "converted_path": output_path,
            "converted_filename": output_filename,
            "timestamp": datetime.now().isoformat()
        })
        if 'converted_videos' not in db[file_id]:
            db[file_id]['converted_videos'] = []
        db[file_id]['converted_videos'].append({
            "path": output_path,
            "filename": os.path.basename(output_path),
            "template_name": f"{target_width}x{target_height}", # ç°¡åŒ–è¡¨ç¤º
            "timestamp": datetime.now().isoformat()
        })
        print(f"âœ… å·²å°‡å½±ç‰‡è½‰æ›è³‡æ–™å„²å­˜è‡³è³‡æ–™åº«: {file_id}")

    return jsonify({
        "success": True,
        "file_id": file_id,
        "download_url": f"/outputs/{output_filename}",
        "filename": output_filename
    })

@app.route('/api/preview_crop', methods=['POST'])
def preview_crop():
    """ç”¢ç”Ÿè£åˆ‡é è¦½åœ–"""
    if not request.is_json:
        return jsonify({"error": "è«‹æ±‚çš„ Content-Type å¿…é ˆæ˜¯ application/json"}), 415

    data = request.json
    base64_image = data.get('thumbnail_data')
    target_width = data.get('target_width')
    target_height = data.get('target_height')
    original_width = data.get('original_width')
    original_height = data.get('original_height')
    center = data.get('center')
    centers = data.get('centers')  # æ”¯æ´å¤šå€‹ä¸­å¿ƒé»
    file_id = data.get('file_id')  # éœ€è¦ file_id ä¾†è¨ˆç®—å¤šä¸»é«”ä¸­å¿ƒé»

    # è™•ç†å¤šé¸ä¸­å¿ƒé»
    if centers and len(centers) > 0 and file_id:
        center = calculate_multi_subject_center_backend(centers, file_id)
        if center:
            center = list(center)  # è½‰æ›ç‚ºåˆ—è¡¨æ ¼å¼

    if not all([base64_image, target_width, target_height, original_width, original_height, center]):
        return jsonify({"error": "ç¼ºå°‘å¿…è¦åƒæ•¸"}), 400

    try:
        # è§£ç¢¼åœ–ç‰‡
        image_data = base64.b64decode(base64_image.split(',')[1])
        img = Image.open(BytesIO(image_data))

        # --- æ²¿ç”¨èˆ‡å½±ç‰‡è½‰æ›å®Œå…¨ç›¸åŒçš„æ™ºæ…§è£åˆ‡é‚è¼¯ ---
        scale = max(target_width / original_width, target_height / original_height)
        resized_w, resized_h = int(original_width * scale), int(original_height * scale)
        resized_img = img.resize((resized_w, resized_h), Image.LANCZOS)
        
        desired_center_x = center[0] * scale
        desired_center_y = center[1] * scale

        half_w, half_h = target_width / 2, target_height / 2
        min_x, max_x = half_w, resized_w - half_w
        min_y, max_h = half_h, resized_h - half_h
        
        final_crop_x = max(min_x, min(desired_center_x, max_x))
        final_crop_y = max(min_y, min(desired_center_y, max_h))
        
        # æª¢æŸ¥ä¸»è§’æ˜¯å¦è¢«è£åˆ‡
        is_subject_cropped = abs(final_crop_x - desired_center_x) > 1 or abs(final_crop_y - desired_center_y) > 1

        # é€²è¡Œè£åˆ‡
        left = final_crop_x - half_w
        top = final_crop_y - half_h
        right = final_crop_x + half_w
        bottom = final_crop_y + half_h
        cropped_img = resized_img.crop((left, top, right, bottom))
        
        # å¦‚æœä¸»è§’è¢«è£åˆ‡ï¼Œç–ŠåŠ ä¸€å€‹ç´…è‰²è­¦å‘Šåœ–å±¤
        if is_subject_cropped:
            overlay = Image.new('RGBA', cropped_img.size, (255, 0, 0, 0)) # é€æ˜
            draw = ImageDraw.Draw(overlay)
            draw.rectangle([(0, 0), (cropped_img.width, cropped_img.height)], 
                          outline=(255, 80, 80, 200), width=10) # ç´…è‰²é‚Šæ¡†
            cropped_img = Image.alpha_composite(cropped_img.convert("RGBA"), overlay)


        # å°‡çµæœè½‰å› Base64
        buffered = BytesIO()
        cropped_img.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        
        return jsonify({
            "preview_image": f"data:image/png;base64,{img_str}",
            "is_cropped": is_subject_cropped
        })

    except Exception as e:
        import traceback
        print(f"âŒ é è¦½è£åˆ‡å¤±æ•—: {e}")
        traceback.print_exc()
        return jsonify({"error": "ç”¢ç”Ÿé è¦½åœ–å¤±æ•—"}), 500

@app.route('/api/smart_crop_analysis', methods=['POST'])
def smart_crop_analysis():
    """æ™ºæ…§è£åˆ‡åˆ†æ - åˆ†æä¸»é«”åœ¨ç‰¹å®šå°ºå¯¸ä¸‹çš„æœ€ä½³è£åˆ‡æ–¹æ¡ˆ"""
    if not request.is_json:
        return jsonify({"error": "è«‹æ±‚çš„ Content-Type å¿…é ˆæ˜¯ application/json"}), 415

    data = request.json
    file_id = data.get('file_id')
    template_name = data.get('template_name')
    center = data.get('center')
    centers = data.get('centers')  # æ”¯æ´å¤šå€‹ä¸­å¿ƒé»

    # è™•ç†å¤šé¸ä¸­å¿ƒé»
    if centers and len(centers) > 0:
        center = calculate_multi_subject_center_backend(centers, file_id)
        if center:
            center = list(center)  # è½‰æ›ç‚ºåˆ—è¡¨æ ¼å¼

    if not all([file_id, template_name, center]):
        return jsonify({"error": "ç¼ºå°‘å¿…è¦åƒæ•¸"}), 400

    # æ‰¾åˆ°æ¨¡æ¿
    template = next((t for t in DOOH_TEMPLATES if t['name'] == template_name), None)
    if not template:
        return jsonify({"error": f"æ‰¾ä¸åˆ°æ¨¡æ¿: {template_name}"}), 404

    # ç²å–å½±ç‰‡è³‡æ–™
    with closing(shelve.open(SHELVE_FILE)) as db:
        video_data = db.get(file_id)
        if not video_data:
            return jsonify({"error": f"æ‰¾ä¸åˆ°å½±ç‰‡è³‡æ–™: {file_id}"}), 404

    video_info = video_data.get('video_info', {})
    original_width = video_info.get('width', 1920)
    original_height = video_info.get('height', 1080)
    
    # åˆ†æè£åˆ‡å¯è¡Œæ€§
    target_width, target_height = template['width'], template['height']
    target_ratio = target_width / target_height
    original_ratio = original_width / original_height
    
    # è¨ˆç®—ç¸®æ”¾æ¯”ä¾‹
    scale = max(target_width / original_width, target_height / original_height)
    scaled_width = original_width * scale
    scaled_height = original_height * scale
    
    # åˆ†æä¸­å¿ƒé»çš„å¯è¡Œæ€§
    desired_center_x = center[0] * scale
    desired_center_y = center[1] * scale
    
    half_w, half_h = target_width / 2, target_height / 2
    min_x, max_x = half_w, scaled_width - half_w
    min_y, max_y = half_h, scaled_height - half_h
    
    final_crop_x = max(min_x, min(desired_center_x, max_x))
    final_crop_y = max(min_y, min(desired_center_y, max_y))
    
    # è¨ˆç®—åç§»é‡
    offset_x = abs(final_crop_x - desired_center_x)
    offset_y = abs(final_crop_y - desired_center_y)
    
    # åˆ†æçµæœ
    is_perfect_fit = offset_x < 1 and offset_y < 1
    coverage_x = min(1.0, target_width / scaled_width) * 100
    coverage_y = min(1.0, target_height / scaled_height) * 100
    
    # ç”Ÿæˆå»ºè­°
    analysis = {
        "is_perfect_fit": is_perfect_fit,
        "offset_x": round(offset_x, 1),
        "offset_y": round(offset_y, 1),
        "coverage_x": round(coverage_x, 1),
        "coverage_y": round(coverage_y, 1),
        "scale_factor": round(scale, 2),
        "recommendation": "å®Œç¾é©é…" if is_perfect_fit else "éœ€è¦èª¿æ•´" if (offset_x > 10 or offset_y > 10) else "è‰¯å¥½é©é…"
    }
    
    return jsonify(analysis)

@app.route('/api/generate_preview', methods=['POST'])
def generate_preview():
    """ç‚º AI æ¨è–¦çš„æ¨¡æ¿ç”Ÿæˆå¤šå¹€é è¦½å‹•ç•«"""
    if not request.is_json:
        return jsonify({"error": "è«‹æ±‚çš„ Content-Type å¿…é ˆæ˜¯ application/json"}), 415

    data = request.json
    file_id = data.get('file_id')
    template_name = data.get('template_name')
    center = data.get('center')
    centers = data.get('centers')  # æ”¯æ´å¤šå€‹ä¸­å¿ƒé»

    if not all([file_id, template_name]):
        return jsonify({"error": "ç¼ºå°‘å¿…è¦åƒæ•¸ (file_id, template_name)"}), 400

    # æ‰¾åˆ°æ¨¡æ¿
    template = next((t for t in DOOH_TEMPLATES if t['name'] == template_name), None)
    if not template:
        return jsonify({"error": f"æ‰¾ä¸åˆ°æ¨¡æ¿: {template_name}"}), 404

    # ç²å–å½±ç‰‡è·¯å¾‘
    upload_path = None
    for f in os.listdir(UPLOAD_FOLDER):
        if f.startswith(file_id):
            upload_path = os.path.join(UPLOAD_FOLDER, f)
            break
    
    if not upload_path:
        return jsonify({"error": f"æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ: {file_id}"}), 404

    # ç²å–å½±ç‰‡è³‡æ–™å’Œ LLM åˆ†æçµæœ
    with closing(shelve.open(SHELVE_FILE)) as db:
        video_data = db.get(file_id)
        if not video_data:
            return jsonify({"error": f"æ‰¾ä¸åˆ°å½±ç‰‡è³‡æ–™: {file_id}"}), 404

    # è™•ç†å¤šé¸ä¸­å¿ƒé»
    if centers and len(centers) > 0:
        center = calculate_multi_subject_center_backend(centers, file_id)
        if center:
            center = list(center)  # è½‰æ›ç‚ºåˆ—è¡¨æ ¼å¼
    
    # ä½¿ç”¨é è¨­ä¸­å¿ƒé»å¦‚æœæ²’æœ‰æä¾›
    if not center:
        video_info = video_data.get('video_info', {})
        center = [video_info.get('width', 1920) / 2, video_info.get('height', 1080) / 2]

    # ç²å– LLM åˆ†æçš„ç‰©é«”è³‡è¨Š
    llm_analysis_options = video_data.get('llm_analysis_options', [])
    selected_subject_name = None
    
    # æ‰¾åˆ°ç•¶å‰é¸ä¸­ä¸»é«”çš„åç¨±
    for option in llm_analysis_options:
        if option.get('center') == center:
            selected_subject_name = option.get('subject', 'Unknown')
            print(f"ğŸ¯ æ‰¾åˆ°é¸ä¸­çš„ä¸»é«”: {selected_subject_name}")
            break

    try:
        # å¾å½±ç‰‡ä¸­æå–å¤šå€‹å¹€
        cap = cv2.VideoCapture(upload_path)
        if not cap.isOpened():
            return jsonify({"error": "ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ"}), 500

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"ğŸ“Š å½±ç‰‡ä¿¡æ¯: total_frames={total_frames}, fps={fps}")
        
        # æå–5-8å€‹é—œéµå¹€
        if total_frames <= 0:
            print(f"âŒ å½±ç‰‡å¹€æ•¸ç‚º 0ï¼Œç„¡æ³•æå–é è¦½")
            return jsonify({"error": "å½±ç‰‡ç„¡æœ‰æ•ˆå¹€"}), 500
            
        num_preview_frames = min(6, max(3, max(1, total_frames // 30)))  # ç¢ºä¿è‡³å°‘æœ‰1å¹€
        if total_frames < 30:
            num_preview_frames = min(total_frames, 3)  # çŸ­å½±ç‰‡ä½¿ç”¨è¼ƒå°‘å¹€æ•¸
        
        frame_indices = []
        if num_preview_frames > 1 and total_frames > 1:
            for i in range(num_preview_frames):
                frame_idx = int(i * (total_frames - 1) / (num_preview_frames - 1))
                frame_indices.append(min(frame_idx, total_frames - 1))  # ç¢ºä¿ä¸è¶…å‡ºç¯„åœ
        else:
            frame_indices = [0]  # åªæœ‰ä¸€å¹€çš„æƒ…æ³
            
        print(f"ğŸ¬ æº–å‚™æå– {len(frame_indices)} å€‹é è¦½å¹€: {frame_indices}")
        
        preview_frames = []
        target_width, target_height = template['width'], template['height']
        is_adjusted = False
        
        for i, frame_idx in enumerate(frame_indices):
            print(f"ğŸ¬ è™•ç†ç¬¬ {i+1}/{len(frame_indices)} å¹€ï¼Œç´¢å¼•: {frame_idx}")
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if not ret:
                print(f"âš ï¸ ç„¡æ³•è®€å–å¹€ {frame_idx}ï¼Œè·³é")
                continue
                
            # è½‰æ›ç‚º PIL Image
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame_rgb)
            original_width, original_height = img.size

            # åŸ·è¡Œè£åˆ‡é‚è¼¯ï¼ˆèˆ‡å½±ç‰‡è½‰æ›ç›¸åŒï¼‰
            scale = max(target_width / original_width, target_height / original_height)
            resized_w, resized_h = int(original_width * scale), int(original_height * scale)
            resized_img = img.resize((resized_w, resized_h), Image.LANCZOS)
            
            desired_center_x = center[0] * scale
            desired_center_y = center[1] * scale

            half_w, half_h = target_width / 2, target_height / 2
            min_x, max_x = half_w, resized_w - half_w
            min_y, max_y = half_h, resized_h - half_h
            
            final_crop_x = max(min_x, min(desired_center_x, max_x))
            final_crop_y = max(min_y, min(desired_center_y, max_y))
            
            # æª¢æŸ¥æ˜¯å¦æœ‰è£åˆ‡èª¿æ•´ï¼ˆåªéœ€è¦æª¢æŸ¥ä¸€æ¬¡ï¼‰
            if not is_adjusted:
                is_adjusted = abs(final_crop_x - desired_center_x) > 1 or abs(final_crop_y - desired_center_y) > 1

            # é€²è¡Œè£åˆ‡
            left = final_crop_x - half_w
            top = final_crop_y - half_h
            right = final_crop_x + half_w
            bottom = final_crop_y + half_h
            cropped_img = resized_img.crop((left, top, right, bottom))
            

            
            # èª¿æ•´é è¦½åœ–å¤§å°ä»¥ä¾¿é¡¯ç¤ºï¼ˆæœ€å¤§å¯¬åº¦250pxï¼‰
            preview_scale = min(250 / target_width, 180 / target_height)
            if preview_scale < 1:
                preview_w = int(target_width * preview_scale)
                preview_h = int(target_height * preview_scale)
                cropped_img = cropped_img.resize((preview_w, preview_h), Image.LANCZOS)

            # å°‡çµæœè½‰ç‚º Base64
            buffered = BytesIO()
            cropped_img.save(buffered, format="JPEG", quality=80)
            img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
            preview_frames.append(f"data:image/jpeg;base64,{img_str}")

        cap.release()
        
        if not preview_frames:
            print(f"âŒ ç„¡æ³•æå–ä»»ä½•é è¦½å¹€ï¼Œtotal_frames={total_frames}, frame_indices={frame_indices}")
            return jsonify({"error": "ç„¡æ³•æå–é è¦½å¹€"}), 500
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(preview_frames)} å€‹é è¦½å¹€")
        return jsonify({
            "preview_frames": preview_frames,
            "is_adjusted": is_adjusted,
            "template": template,
            "frame_count": len(preview_frames),
            "subject_name": selected_subject_name
        })

    except Exception as e:
        import traceback
        print(f"âŒ ç”Ÿæˆå¤šå¹€é è¦½å¤±æ•—: {e}")
        traceback.print_exc()
        return jsonify({"error": "ç”Ÿæˆé è¦½å¤±æ•—"}), 500

@app.route('/api/generate_original_preview', methods=['POST'])
def generate_original_preview():
    """ç‚ºåŸå§‹å½±ç‰‡ç”Ÿæˆå‹•æ…‹é è¦½"""
    if not request.is_json:
        return jsonify({"error": "è«‹æ±‚çš„ Content-Type å¿…é ˆæ˜¯ application/json"}), 415

    data = request.json
    file_id = data.get('file_id')

    if not file_id:
        return jsonify({"error": "ç¼ºå°‘å¿…è¦åƒæ•¸ (file_id)"}), 400

    # ç²å–å½±ç‰‡è·¯å¾‘
    upload_path = None
    for f in os.listdir(UPLOAD_FOLDER):
        if f.startswith(file_id):
            upload_path = os.path.join(UPLOAD_FOLDER, f)
            break
    
    if not upload_path:
        return jsonify({"error": f"æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆ: {file_id}"}), 404

    try:
        # å¾å½±ç‰‡ä¸­æå–å¤šå€‹å¹€ç”¨æ–¼å‹•æ…‹é è¦½
        cap = cv2.VideoCapture(upload_path)
        if not cap.isOpened():
            return jsonify({"error": "ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ"}), 500

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"ğŸ“Š åŸå§‹å½±ç‰‡ä¿¡æ¯: total_frames={total_frames}, fps={fps}")
        
        # æå–5-8å€‹é—œéµå¹€
        if total_frames <= 0:
            print(f"âŒ å½±ç‰‡å¹€æ•¸ç‚º 0ï¼Œç„¡æ³•æå–é è¦½")
            return jsonify({"error": "å½±ç‰‡ç„¡æœ‰æ•ˆå¹€"}), 500
            
        num_preview_frames = min(8, max(4, max(1, total_frames // 20)))  # æ›´å¤šå¹€æ•¸ç”¨æ–¼åŸå§‹é è¦½
        if total_frames < 20:
            num_preview_frames = min(total_frames, 4)  # çŸ­å½±ç‰‡ä½¿ç”¨è¼ƒå°‘å¹€æ•¸
        
        frame_indices = []
        if num_preview_frames > 1 and total_frames > 1:
            for i in range(num_preview_frames):
                frame_idx = int(i * (total_frames - 1) / (num_preview_frames - 1))
                frame_indices.append(min(frame_idx, total_frames - 1))  # ç¢ºä¿ä¸è¶…å‡ºç¯„åœ
        else:
            frame_indices = [0]  # åªæœ‰ä¸€å¹€çš„æƒ…æ³
            
        print(f"ğŸ¬ æº–å‚™æå–åŸå§‹å½±ç‰‡ {len(frame_indices)} å€‹é è¦½å¹€: {frame_indices}")
        
        preview_frames = []
        
        for i, frame_idx in enumerate(frame_indices):
            print(f"ğŸ¬ è™•ç†åŸå§‹å½±ç‰‡ç¬¬ {i+1}/{len(frame_indices)} å¹€ï¼Œç´¢å¼•: {frame_idx}")
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if not ret:
                print(f"âš ï¸ ç„¡æ³•è®€å–å¹€ {frame_idx}ï¼Œè·³é")
                continue
                
            # è½‰æ›ç‚º PIL Image
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame_rgb)
            
            # èª¿æ•´é è¦½åœ–å¤§å°ä»¥ä¾¿é¡¯ç¤ºï¼ˆæœ€å¤§å¯¬åº¦300pxï¼Œä¿æŒæ¯”ä¾‹ï¼‰
            original_width, original_height = img.size
            max_width = 300
            if original_width > max_width:
                scale = max_width / original_width
                preview_w = int(original_width * scale)
                preview_h = int(original_height * scale)
                img = img.resize((preview_w, preview_h), Image.LANCZOS)

            # å°‡çµæœè½‰ç‚º Base64
            buffered = BytesIO()
            img.save(buffered, format="JPEG", quality=85)
            img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
            preview_frames.append(f"data:image/jpeg;base64,{img_str}")

        cap.release()
        
        if not preview_frames:
            print(f"âŒ ç„¡æ³•æå–ä»»ä½•åŸå§‹é è¦½å¹€ï¼Œtotal_frames={total_frames}, frame_indices={frame_indices}")
            return jsonify({"error": "ç„¡æ³•æå–é è¦½å¹€"}), 500
        
        print(f"âœ… æˆåŠŸç”ŸæˆåŸå§‹å½±ç‰‡ {len(preview_frames)} å€‹é è¦½å¹€")
        return jsonify({
            "preview_frames": preview_frames,
            "frame_count": len(preview_frames)
        })

    except Exception as e:
        import traceback
        print(f"âŒ ç”ŸæˆåŸå§‹å½±ç‰‡é è¦½å¤±æ•—: {e}")
        traceback.print_exc()
        return jsonify({"error": "ç”ŸæˆåŸå§‹å½±ç‰‡é è¦½å¤±æ•—"}), 500

@app.route('/uploads/<path:filename>')
def serve_upload_video(filename):
    """æä¾›åŸå§‹ä¸Šå‚³çš„å½±ç‰‡æª”æ¡ˆ"""
    return send_from_directory(UPLOAD_FOLDER, filename)

@app.route('/outputs/<path:filename>')
def serve_output_video(filename):
    """æä¾›è½‰æ›å¾Œçš„å½±ç‰‡æª”æ¡ˆ"""
    return send_from_directory(OUTPUT_FOLDER, filename)

# --- Main ---
if __name__ == '__main__':
    # try:
    #     from waitress import serve
    #     print("ğŸš€ ä½¿ç”¨ Waitress ç”Ÿç”¢ç’°å¢ƒä¼ºæœå™¨å•Ÿå‹•æ–¼ http://0.0.0.0:5001")
    #     serve(app, host='0.0.0.0', port=5001, threads=8)
    # except ImportError:
    #     print("âš ï¸ Waitress æœªå®‰è£ï¼Œä½¿ç”¨ Flask é–‹ç™¼ä¼ºæœå™¨ã€‚")
    #     print("ğŸ‘‰ å»ºè­°å®‰è£ä»¥ç²å¾—æ›´ä½³æ€§èƒ½: pip install waitress")
    print("ğŸš€ ä½¿ç”¨ Flask é–‹ç™¼ä¼ºæœå™¨å•Ÿå‹• (é™¤éŒ¯æ¨¡å¼)")
    app.run(debug=True, host='0.0.0.0', port=5001, use_reloader=False)